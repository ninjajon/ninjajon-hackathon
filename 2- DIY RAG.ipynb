{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate - RAG with Vector Search and BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/retrieval-augmented-generation/Document_QnA_using_gemini_and_vector_search.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.83.0-py2.py3-none-any.whl.metadata (33 kB)\n",
      "Collecting google-cloud-bigquery\n",
      "  Downloading google_cloud_bigquery-3.30.0-py2.py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting db-dtypes\n",
      "  Downloading db_dtypes-1.4.2-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.19-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Using cached google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-auth<3.0.0dev,>=2.14.1 (from google-cloud-aiplatform)\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-cloud-aiplatform)\n",
      "  Using cached proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-aiplatform)\n",
      "  Using cached protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/google/home/jolefebvre/Code/gcp-cn-hackathon/.venv/lib/python3.12/site-packages (from google-cloud-aiplatform) (24.2)\n",
      "Collecting google-cloud-storage<3.0.0dev,>=1.32.0 (from google-cloud-aiplatform)\n",
      "  Using cached google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform)\n",
      "  Downloading google_cloud_resource_manager-1.14.1-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform)\n",
      "  Downloading shapely-2.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting pydantic<3 (from google-cloud-aiplatform)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting typing-extensions (from google-cloud-aiplatform)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting docstring-parser<1 (from google-cloud-aiplatform)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-cloud-core<3.0.0dev,>=2.4.1 (from google-cloud-bigquery)\n",
      "  Downloading google_cloud_core-2.4.2-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media<3.0dev,>=2.0.0 (from google-cloud-bigquery)\n",
      "  Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in /usr/local/google/home/jolefebvre/Code/gcp-cn-hackathon/.venv/lib/python3.12/site-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
      "Collecting requests<3.0.0dev,>=2.21.0 (from google-cloud-bigquery)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pandas>=0.24.2 (from db-dtypes)\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting pyarrow>=3.0.0 (from db-dtypes)\n",
      "  Downloading pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting numpy>=1.16.6 (from db-dtypes)\n",
      "  Downloading numpy-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.41 (from langchain)\n",
      "  Downloading langchain_core-0.3.43-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.13-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.38-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.11.13-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain-community)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.5.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading googleapis_common_protos-1.69.1-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading grpcio-1.71.0rc2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform)\n",
      "  Downloading grpcio_status-1.71.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.14.0 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform)\n",
      "  Downloading grpc_google_iam_v1-0.14.1-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform)\n",
      "  Downloading google_crc32c-1.6.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.41->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=0.24.2->db-dtypes)\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=0.24.2->db-dtypes)\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->google-cloud-aiplatform)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3->google-cloud-aiplatform)\n",
      "  Downloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/google/home/jolefebvre/Code/gcp-cn-hackathon/.venv/lib/python3.12/site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery) (1.17.0)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery)\n",
      "  Downloading charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m217.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_aiplatform-1.83.0-py2.py3-none-any.whl (7.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m148.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_bigquery-3.30.0-py2.py3-none-any.whl (247 kB)\n",
      "Downloading db_dtypes-1.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Downloading langchain-0.3.20-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.19-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.13-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "Using cached google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Downloading google_cloud_core-2.4.2-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_cloud_resource_manager-1.14.1-py2.py3-none-any.whl (392 kB)\n",
      "Using cached google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
      "Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain_core-0.3.43-py3-none-any.whl (415 kB)\n",
      "Downloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Downloading langsmith-0.3.13-py3-none-any.whl (339 kB)\n",
      "Downloading numpy-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "Using cached protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading pyarrow-19.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading shapely-2.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.38-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m125.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading aiohappyeyeballs-2.5.0-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (145 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "Downloading google_crc32c-1.6.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Downloading googleapis_common_protos-1.69.1-py2.py3-none-any.whl (293 kB)\n",
      "Downloading greenlet-3.1.1-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (613 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.1/613.1 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpc_google_iam_v1-0.14.1-py2.py3-none-any.whl (19 kB)\n",
      "Downloading grpcio-1.71.0rc2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m153.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.71.0rc2-py3-none-any.whl (14 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Downloading orjson-3.10.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Downloading propcache-0.3.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
      "Downloading zstandard-0.23.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: pytz, zstandard, urllib3, tzdata, typing-extensions, tenacity, sniffio, PyYAML, python-dotenv, pymupdf, pyasn1, pyarrow, protobuf, propcache, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpointer, idna, httpx-sse, h11, grpcio, greenlet, google-crc32c, frozenlist, docstring-parser, charset-normalizer, certifi, cachetools, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, shapely, rsa, requests, pydantic-core, pyasn1-modules, proto-plus, pandas, jsonpatch, httpcore, googleapis-common-protos, google-resumable-media, anyio, aiosignal, requests-toolbelt, pydantic, httpx, grpcio-status, google-auth, db-dtypes, dataclasses-json, aiohttp, pydantic-settings, langsmith, grpc-google-iam-v1, google-api-core, langchain-core, google-cloud-core, langchain-text-splitters, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, langchain, google-cloud-aiplatform, langchain-community\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.38 aiohappyeyeballs-2.5.0 aiohttp-3.11.13 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.8.0 attrs-25.1.0 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 dataclasses-json-0.6.7 db-dtypes-1.4.2 docstring-parser-0.16 frozenlist-1.5.0 google-api-core-2.24.1 google-auth-2.38.0 google-cloud-aiplatform-1.83.0 google-cloud-bigquery-3.30.0 google-cloud-core-2.4.2 google-cloud-resource-manager-1.14.1 google-cloud-storage-2.19.0 google-crc32c-1.6.0 google-resumable-media-2.7.2 googleapis-common-protos-1.69.1 greenlet-3.1.1 grpc-google-iam-v1-0.14.1 grpcio-1.71.0rc2 grpcio-status-1.71.0rc2 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 httpx-sse-0.4.0 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.20 langchain-community-0.3.19 langchain-core-0.3.43 langchain-text-splitters-0.3.6 langsmith-0.3.13 marshmallow-3.26.1 multidict-6.1.0 mypy-extensions-1.0.0 numpy-2.2.3 orjson-3.10.15 pandas-2.2.3 propcache-0.3.0 proto-plus-1.26.0 protobuf-5.29.3 pyarrow-19.0.1 pyasn1-0.6.1 pyasn1-modules-0.4.1 pydantic-2.10.6 pydantic-core-2.27.2 pydantic-settings-2.8.1 pymupdf-1.25.3 python-dotenv-1.0.1 pytz-2025.1 requests-2.32.3 requests-toolbelt-1.0.0 rsa-4.9 shapely-2.0.7 sniffio-1.3.1 tenacity-9.0.0 typing-extensions-4.12.2 typing-inspect-0.9.0 tzdata-2025.1 urllib3-2.3.0 yarl-1.18.3 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pymupdf \\\n",
    "    google-cloud-aiplatform \\\n",
    "    google-cloud-bigquery \\\n",
    "    db-dtypes \\\n",
    "    langchain \\\n",
    "    langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables and initialize Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define project information\n",
    "PROJECT_ID = \"jo-cn-hackathon-qqal\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "VECTOR_SEARCH_REGION = \"us-central1\"\n",
    "VECTOR_SEARCH_INDEX_NAME = f\"{PROJECT_ID}-rregop-index\"\n",
    "VECTOR_SEARCH_INDEX_ENDPOINT_NAME = f\"{PROJECT_ID}-rregop-index-endpoint\"\n",
    "VECTOR_SEARCH_EMBEDDING_BUCKET = f\"{PROJECT_ID}-rregop-vector-search-bucket\"\n",
    "VECTOR_SEARCH_DIMENSIONS = 768\n",
    "BQ_DATASET = \"rregop_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set gcloud configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud config set project {PROJECT_ID} --quiet\n",
    "! gcloud config set run/region {LOCATION} --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "# File system operations and displaying images\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Import utility functions for timing and file handling\n",
    "import time\n",
    "\n",
    "# Libraries for downloading files, data manipulation, and creating a user interface\n",
    "import uuid\n",
    "\n",
    "import fitz\n",
    "\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Initialize Vertex AI libraries for working with generative models\n",
    "from google.cloud import aiplatform\n",
    "import pandas as pd\n",
    "from vertexai.generative_models import GenerativeModel, Image\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "# Print Vertex AI SDK version\n",
    "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Gemini 1.5 Pro and Text Embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Gemini 1.5 Pro Model\n",
    "multimodal_model = GenerativeModel(\"gemini-1.5-flash-002\")\n",
    "\n",
    "# Initializing embedding model\n",
    "text_embedding_model = TextEmbeddingModel.from_pretrained(\"text-multilingual-embedding-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split PDF files to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an \"Images\" directory if it doesn't exist\n",
    "data_path = \"../data\"\n",
    "\n",
    "# Create an \"Images\" directory if it doesn't exist\n",
    "images_path = f\"{data_path}/images/\"\n",
    "if not os.path.exists(images_path):\n",
    "    os.makedirs(images_path)\n",
    "else:\n",
    "    print(f\"Images directory already exists: {images_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get better resolution\n",
    "zoom_x = 2.0  # horizontal zoom\n",
    "zoom_y = 2.0  # vertical zoom\n",
    "mat = fitz.Matrix(zoom_x, zoom_y)  # zoom factor 2 in each dimension\n",
    "\n",
    "# Get list of PDF files in data folder\n",
    "pdf_files = [f for f in os.listdir(data_path) if f.endswith('.pdf')]\n",
    "\n",
    "# Process each PDF file\n",
    "for pdf_file in pdf_files:\n",
    "    doc = fitz.open(f\"{data_path}/{pdf_file}\")  # open document\n",
    "    for page in doc:  # iterate through the pages\n",
    "        pix = page.get_pixmap(matrix=mat)  # render page to an image\n",
    "        outpath = f\"{images_path}/{pdf_file}_{page.number}.jpg\"\n",
    "        pix.save(outpath)  # store image as a PNG\n",
    "    doc.close()  # close the document after processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data using Gemini Vision Pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module processes a set of images, extracting text and tabular data using a multimodal model (Gemini 1.5 Pro). It handles potential errors, stores the extracted information in a DataFrame, and saves the results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path where images are located\n",
    "image_names = os.listdir(images_path)\n",
    "max_images = len(image_names)\n",
    "print(f\"Processing {max_images} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store image information\n",
    "page_source = []\n",
    "page_content = []\n",
    "page_id = []\n",
    "\n",
    "p_id = 0  # Initialize image ID counter\n",
    "rest_count = 0  # Initialize counter for error handling\n",
    "\n",
    "while p_id < max_images:\n",
    "    try:\n",
    "        # Construct the full path to the current image\n",
    "        image_path = images_path + image_names[p_id]\n",
    "        print(f\"Processing image: {image_path}\")\n",
    "\n",
    "        # Load the image\n",
    "        image = Image.load_from_file(image_path)\n",
    "\n",
    "        # Generate prompts for text and table extraction\n",
    "        prompt_text = \"Extract all text content in the image\"\n",
    "        prompt_table = (\n",
    "            \"Detect table in this image. Extract content maintaining the structure\"\n",
    "        )\n",
    "\n",
    "        # Extract text using your multimodal model\n",
    "        contents = [image, prompt_text]\n",
    "        response = multimodal_model.generate_content(contents)\n",
    "        text_content = response.text\n",
    "\n",
    "        # Extract table using your multimodal model\n",
    "        contents = [image, prompt_table]\n",
    "        response = multimodal_model.generate_content(contents)\n",
    "        table_content = response.text\n",
    "\n",
    "        # Log progress and store results\n",
    "        print(f\"processed image no: {p_id}\")\n",
    "        page_source.append(image_path)\n",
    "        page_content.append(text_content + \"\\n\" + table_content)\n",
    "        page_id.append(p_id)\n",
    "        p_id += 1\n",
    "\n",
    "    except Exception as err:\n",
    "        # Handle errors during processing\n",
    "        print(err)\n",
    "        print(\"Taking Some Rest\")\n",
    "        time.sleep(1)  # Pause execution for 1 second\n",
    "        rest_count += 1\n",
    "        if rest_count == 5:  # Limit consecutive error handling\n",
    "            rest_count = 0\n",
    "            print(f\"Cannot process image no: {image_path}\")\n",
    "            p_id += 1  # Move to the next image\n",
    "\n",
    "# Create a DataFrame to store extracted information\n",
    "df = pd.DataFrame(\n",
    "    {\"page_id\": page_id, \"page_source\": page_source, \"page_content\": page_content}\n",
    ")\n",
    "del page_id, page_source, page_content  # Conserve memory\n",
    "df.head()  # Preview the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Text Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leverage a powerful language model textembedding-gecko to generate rich text embeddings that helps us find relevant information from a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_embedding(text) -> list:\n",
    "    \"\"\"Text embedding with a Large Language Model.\"\"\"\n",
    "    embeddings = text_embedding_model.get_embeddings([text])\n",
    "    vector = embeddings[0].values\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create BigQuery dataset and GCS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BigQuery dataset if it doesn't exist\n",
    "bq_client = bigquery.Client()\n",
    "dataset_ref = bq_client.dataset(BQ_DATASET)\n",
    "\n",
    "# Check if dataset exists by listing all datasets and checking if BQ_DATASET is in the list\n",
    "datasets = list(bq_client.list_datasets())\n",
    "dataset_exists = any(dataset.dataset_id == BQ_DATASET for dataset in datasets)\n",
    "\n",
    "if not dataset_exists:\n",
    "    # Construct a Dataset object to send to the API\n",
    "    dataset = bigquery.Dataset(dataset_ref)\n",
    "    dataset.location = \"US\"  # Specify the location\n",
    "    \n",
    "    try:\n",
    "        # API request to create dataset\n",
    "        dataset = bq_client.create_dataset(dataset)\n",
    "        print(f\"Dataset {BQ_DATASET} created successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating dataset: {str(e)}\")\n",
    "        raise\n",
    "else:\n",
    "    print(f\"Dataset {BQ_DATASET} already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GCS bucket if it doesn't exist\n",
    "gcs_client = storage.Client()\n",
    "bucket = gcs_client.bucket(VECTOR_SEARCH_EMBEDDING_BUCKET)\n",
    "if not bucket.exists():\n",
    "    bucket = gcs_client.create_bucket(\n",
    "        VECTOR_SEARCH_EMBEDDING_BUCKET,\n",
    "        location=VECTOR_SEARCH_REGION  # Specify us-central1 as the location\n",
    "    )\n",
    "    print(f\"Bucket {VECTOR_SEARCH_EMBEDDING_BUCKET} created successfully\")\n",
    "else:\n",
    "    print(f\"Bucket {VECTOR_SEARCH_EMBEDDING_BUCKET} already exists\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate embeddings and store in BigQuery and GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_id = str(random.randint(100000, 999999))\n",
    "\n",
    "# Create a DataFrameLoader to prepare data for LangChain\n",
    "loader = DataFrameLoader(df, page_content_column=\"page_content\")\n",
    "\n",
    "# Load documents from the 'page_content' column of your DataFrame\n",
    "documents = loader.load()\n",
    "\n",
    "# Log the number of documents loaded\n",
    "print(f\"# of documents loaded (pre-chunking) = {len(documents)}\")\n",
    "\n",
    "# Create a text splitter to divide documents into smaller chunks\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=10000,  # Target size of approximately 10000 characters per chunk\n",
    "    chunk_overlap=200,  # overlap between chunks\n",
    ")\n",
    "\n",
    "# Split the loaded documents\n",
    "doc_splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# Add a 'chunk' ID to each document split's metadata for tracking\n",
    "for idx, split in enumerate(doc_splits):\n",
    "    split.metadata[\"chunk\"] = idx\n",
    "\n",
    "# Log the number of documents after splitting\n",
    "print(f\"# of documents = {len(doc_splits)}\")\n",
    "\n",
    "texts = [doc.page_content for doc in doc_splits]\n",
    "text_embeddings_list = []\n",
    "id_list = []\n",
    "page_source_list = []\n",
    "for doc in doc_splits:\n",
    "    id = uuid.uuid4()\n",
    "    text_embeddings_list.append(generate_text_embedding(doc.page_content))\n",
    "    id_list.append(str(id))\n",
    "    page_source_list.append(doc.metadata[\"page_source\"])\n",
    "    time.sleep(1)  # So that we don't run into Quota Issue\n",
    "\n",
    "bq_client = bigquery.Client()\n",
    "\n",
    "# Prepare data for BigQuery and Vector Search\n",
    "rows_to_insert = []\n",
    "index_data = []\n",
    "\n",
    "for doc, embedding in zip(doc_splits, text_embeddings_list):\n",
    "    doc_id = str(uuid.uuid4())\n",
    "    \n",
    "    # Prepare BigQuery row\n",
    "    rows_to_insert.append({\n",
    "        \"id\": doc_id,\n",
    "        \"embedding\": embedding,  # Already a list from generate_text_embedding()\n",
    "        \"page_source\": doc.metadata[\"page_source\"],\n",
    "        \"text\": doc.page_content,\n",
    "        \"execution_id\": execution_id\n",
    "    })\n",
    "\n",
    "    # Prepare data for Vector Search\n",
    "    index_data.append({\n",
    "        \"id\": doc_id,\n",
    "        \"embedding\": embedding\n",
    "    })\n",
    "\n",
    "# Upload to BigQuery\n",
    "table_id = f\"{PROJECT_ID}.{BQ_DATASET}.document_embeddings\"\n",
    "table = bigquery.Table(table_id, schema=[\n",
    "    bigquery.SchemaField(\"id\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"embedding\", \"FLOAT64\", mode=\"REPEATED\"),\n",
    "    bigquery.SchemaField(\"page_source\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"text\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"execution_id\", \"STRING\")\n",
    "])\n",
    "table = bq_client.create_table(table, exists_ok=True)\n",
    "\n",
    "errors = bq_client.insert_rows_json(table, rows_to_insert)\n",
    "if errors:\n",
    "    print(\"BigQuery Errors:\", errors)\n",
    "\n",
    "print(\"Data stored successfully in BigQuery\")\n",
    "\n",
    "# Convert index_data to JSON and store in GCS\n",
    "embeddings_path = f\"{data_path}/embeddings/\"\n",
    "if not os.path.exists(embeddings_path):\n",
    "    os.makedirs(embeddings_path)\n",
    "\n",
    "# save id and embedding as a json file\n",
    "# Convert list of dicts to JSON string directly\n",
    "jsonl_string = \"\\n\".join(json.dumps(record) for record in index_data)\n",
    "with open(f\"{embeddings_path}/data.json\", \"w\") as f:\n",
    "    f.write(jsonl_string)\n",
    "\n",
    "# show the first few lines of the json file\n",
    "! head -n 3 \"{embeddings_path}/data.json\"\n",
    "\n",
    "#send to GCS\n",
    "! gsutil cp {embeddings_path}/data.json gs://{VECTOR_SEARCH_EMBEDDING_BUCKET}/embeddings-{execution_id}/data.json\n",
    "\n",
    "print(f\"Data stored successfully in GCS: gs://{VECTOR_SEARCH_EMBEDDING_BUCKET}/embeddings-{execution_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and deploy a Vector Search Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code configures and deploys a vector search index on Google Cloud, making it ready to store and search through embeddings.\n",
    "\n",
    "Embedding size : The number of values used to represent a piece of text in vector form. Larger dimensions mean a denser and potentially more expressive representation.\n",
    "\n",
    "Dimensions vs. Latency\n",
    "\n",
    "Search: Higher-dimensional embeddings can make vector similarity searches slower, especially in large databases.\n",
    "Computation: Calculations with larger vectors generally take more time during model training and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's ready to load the embeddings to Vector Search. Its APIs are available under the aiplatform package of the SDK.\n",
    "\n",
    "Create an MatchingEngineIndex with its create_tree_ah_index function (Matching Engine is the previous name of Vector Search).\n",
    "\n",
    "By calling the create_tree_ah_index function, it starts building an Index. This will take under a few minutes if the dataset is small, otherwise about 50 minutes or more depending on the size of the dataset. You can check status of the index creation on the [Vector Search Console > INDEXES tab](https://console.cloud.google.com/vertex-ai/matching-engine/indexes).\n",
    "\n",
    "The parameters for creating index:\n",
    "- `contents_delta_uri`: The URI of Cloud Storage directory where you stored the embedding JSON files  \n",
    "- `dimensions`: Dimension size of each embedding. In this case, it is 768 as we are using the embeddings from the Text Embeddings API.\n",
    "- `approximate_neighbors_count`: how many similar items we want to retrieve in typical cases\n",
    "- `distance_measure_type`: what metrics to measure distance/similarity between embeddings. In this case it's DOT_PRODUCT_DISTANCE\n",
    "\n",
    "See the document for more details on creating Index and the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if an index with the same display name already exists\n",
    "indexes = aiplatform.MatchingEngineIndex.list(\n",
    "    filter=f\"display_name={VECTOR_SEARCH_INDEX_NAME}\"\n",
    ")\n",
    "\n",
    "BUCKET_URI = f\"gs://{VECTOR_SEARCH_EMBEDDING_BUCKET}/embeddings-{execution_id}\"\n",
    "\n",
    "if indexes:\n",
    "    # If an index with the same display name exists, update it using batch update\n",
    "    my_index = indexes[0]\n",
    "    my_index.update_embeddings(\n",
    "        contents_delta_uri=BUCKET_URI,\n",
    "    )\n",
    "    print(f\"Index with display name {VECTOR_SEARCH_INDEX_NAME} updated.\")\n",
    "else:\n",
    "    # If no index with the same display name exists, create a new one\n",
    "    my_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "        display_name=f\"{VECTOR_SEARCH_INDEX_NAME}\",\n",
    "        contents_delta_uri=BUCKET_URI,\n",
    "        dimensions=768,\n",
    "        approximate_neighbors_count=20,\n",
    "        distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "    )\n",
    "    print(f\"Index with display name {VECTOR_SEARCH_INDEX_NAME} created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an Index Endpoint and deploy the Index to it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the Index, you need to create an `Index Endpoint`. It works as a server instance accepting query requests for your Index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if an index endpoint with the same display name already exists\n",
    "index_endpoints = aiplatform.MatchingEngineIndexEndpoint.list(\n",
    "    filter=f\"display_name={VECTOR_SEARCH_INDEX_ENDPOINT_NAME}\"\n",
    ")\n",
    "\n",
    "if index_endpoints:\n",
    "    my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "        index_endpoint_name=index_endpoints[0].name\n",
    "    )\n",
    "    print(f\"Index endpoint with display name {index_endpoints[0].display_name} already exists.\")\n",
    "else:\n",
    "    # If no index endpoint with the same display name exists, create a new one\n",
    "    my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "        display_name=f\"{VECTOR_SEARCH_INDEX_ENDPOINT_NAME}\",\n",
    "        public_endpoint_enabled=True,\n",
    "    )\n",
    "    print(f\"Index endpoint with display name {VECTOR_SEARCH_INDEX_ENDPOINT_NAME} created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial utilizes a `Public Endpoint` and does not support Virtual Private Cloud (VPC). Unless you have a specific requirement for VPC, we recommend using a Public Endpoint. Despite the term \"public\" in its name, it does not imply open access to the public internet. Rather, it functions like other endpoints in Vertex AI services, which are secured by default through IAM. Without explicit IAM permissions, as we have previously established, no one can access the endpoint.\n",
    "\n",
    "With the Index Endpoint, deploy the Index by specifying an unique deployed index ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYED_INDEX_ID = f\"{VECTOR_SEARCH_INDEX_NAME}_{execution_id}\"\n",
    "DEPLOYED_INDEX_ID = DEPLOYED_INDEX_ID.replace(\n",
    "    \"-\", \"_\"\n",
    ")  # Can't have - in deployment name, only alphanumeric and _ allowed\n",
    "\n",
    "# deploy the Index to the Index Endpoint\n",
    "deployed_indexes = my_index_endpoint.deployed_indexes\n",
    "if deployed_indexes:\n",
    "    print(f\"Index {DEPLOYED_INDEX_ID} is already deployed.\")\n",
    "else:\n",
    "    my_index_endpoint.deploy_index(index=my_index, deployed_index_id=DEPLOYED_INDEX_ID)\n",
    "    print(f\"Index {DEPLOYED_INDEX_ID} has been deployed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it is the first time to deploy an Index to an Index Endpoint, it will take around 25 minutes to automatically build and initiate the backend for it. After the first deployment, it will finish in seconds. To see the status of the index deployment, open the [Vector Search Console > INDEX ENDPOINTS tab](https://console.cloud.google.com/vertex-ai/matching-engine/index-endpoints) and click the Index Endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_answer(question: str):\n",
    "    # 1. Generate embedding for the question\n",
    "    question_embedding = generate_text_embedding(question)\n",
    "\n",
    "    print(f\"Question embedding: {question_embedding}\")\n",
    "\n",
    "    # 2. Search in Vector Search\n",
    "    response = my_index_endpoint.find_neighbors(\n",
    "        deployed_index_id=DEPLOYED_INDEX_ID,\n",
    "        queries=[question_embedding],\n",
    "        num_neighbors=3\n",
    "    )\n",
    "    \n",
    "    # 3. Get matching document IDs\n",
    "    matched_ids = [neighbor.id for neighbor in response[0]]\n",
    "    \n",
    "    # 4. Query BigQuery to get the actual content\n",
    "    query = f\"\"\"\n",
    "    SELECT text\n",
    "    FROM `{PROJECT_ID}.{BQ_DATASET}.document_embeddings`\n",
    "    WHERE id IN UNNEST({matched_ids})\n",
    "    \"\"\"\n",
    "    \n",
    "    df_results = bq_client.query(query).to_dataframe()\n",
    "    context = \"\\n\".join(df_results['text'].tolist())\n",
    "    \n",
    "    # 5. Generate response with Gemini\n",
    "    prompt = f\"\"\"Based on the following context, please answer the question. \n",
    "    If the answer cannot be found in the context, say \"I cannot find information about this in the provided documents.\"\n",
    "    \n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = multimodal_model.generate_content(prompt)\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question embedding: [-0.006713328417390585, 0.01826227270066738, -0.017548376694321632, -0.008790664374828339, 0.04660380259156227, 0.020247919484972954, -0.010362439788877964, -0.006213292013853788, -0.005355918779969215, 0.008916757069528103, -0.027919145300984383, 0.030738044530153275, -0.02374914102256298, -0.02460528537631035, -0.05231049656867981, -0.0029622011352330446, 0.005142012145370245, -0.027832360938191414, 0.0053589059971272945, 0.02847324125468731, -0.017501456663012505, -0.02481982670724392, 0.025588447228074074, -0.02891330048441887, -0.016972579061985016, -0.0362677127122879, 0.011463724076747894, -0.05470849946141243, -0.01264912262558937, 0.04799213260412216, 0.04327404126524925, 0.021555010229349136, -0.05793343111872673, 0.006443563383072615, 0.026558129116892815, -0.02362137846648693, 0.03936624899506569, 0.03031410090625286, -0.004219745751470327, 0.07515201717615128, -0.03086763620376587, -0.025475244969129562, 0.04131973907351494, 0.01190003752708435, -0.07580284774303436, -0.047803960740566254, 0.015229812823235989, -0.012538217008113861, 0.019872328266501427, 0.026312975212931633, 0.026889100670814514, 0.013408868573606014, -0.06636465340852737, 0.016037777066230774, 0.08610598742961884, -0.05157344043254852, 0.07910601049661636, -0.03185632452368736, 0.10286078602075577, 0.09068567305803299, 0.059634968638420105, 0.041533034294843674, 0.0178221445530653, 0.012752247974276543, 0.04811890050768852, 0.03294680640101433, -0.005691067315638065, -0.02952202595770359, 0.01800110936164856, 0.046179722994565964, -0.02032044157385826, 0.014405446127057076, 0.0011538651306182146, 0.012352111749351025, 0.018883327022194862, -0.011584460735321045, -0.007987109012901783, -0.025040462613105774, -0.00501322653144598, -0.002300516702234745, -0.033658865839242935, 0.05585275590419769, -0.037253931164741516, 0.04253697395324707, 0.04579481482505798, -0.03355477377772331, 0.017891665920615196, -0.12027721107006073, 0.010713279247283936, -0.03461502864956856, -0.0328492671251297, -0.005893659312278032, -0.0186136644333601, 0.07396061718463898, 0.027989022433757782, 0.01146372128278017, 0.026151930913329124, 0.012874092906713486, 0.014325178228318691, -0.02302100695669651, 0.009514343924820423, 0.008357587270438671, 0.04239922761917114, -0.036242738366127014, 0.059464409947395325, -0.017591314390301704, -0.012181206606328487, 0.04568885639309883, 0.025555092841386795, 0.05582580342888832, -0.03752337768673897, -0.017279496416449547, -0.013031285256147385, -0.015848586335778236, -0.03313988074660301, 0.02640770934522152, 0.004991033114492893, 0.019839197397232056, -0.04452383145689964, -0.004551684018224478, 0.0021433562505990267, 0.05010257288813591, -0.07005935162305832, -0.05270770937204361, 0.0402458980679512, -0.033563144505023956, -0.020698318257927895, -0.06503648310899734, 0.01550409197807312, 0.022042138502001762, 0.07875242084264755, 0.09005814045667648, 0.014790501445531845, 0.016455113887786865, 0.0028728677425533533, -0.025153880938887596, 0.03543587774038315, 0.004773529712110758, 0.06417903304100037, 0.02000434882938862, -0.010156555101275444, 0.027580713853240013, -0.021853044629096985, 0.028068289160728455, -0.03606335446238518, -0.02670755423605442, -0.035887036472558975, 0.04600590094923973, -0.04928315058350563, 0.0011663442710414529, -0.02213340811431408, -0.03405449166893959, 0.06483267992734909, -0.05185830220580101, -0.057873647660017014, -0.01738918386399746, -0.041229650378227234, 0.09044688194990158, 0.08778221905231476, -0.06034427136182785, 0.04962528869509697, -0.0027364231646060944, -0.0053682527504861355, -0.07075455039739609, 0.03388698771595955, -0.06505909562110901, 0.017795544117689133, 0.016965964809060097, -0.02925475873053074, 0.02088077738881111, -0.030653592199087143, 0.0863734558224678, 0.045756492763757706, -0.00933739822357893, -0.007742546498775482, 0.05588805302977562, 0.00863609742373228, -0.06438883394002914, 0.05653616040945053, -0.03411591053009033, 0.003541309153661132, 0.021580791100859642, 0.04335666447877884, 0.030783602967858315, -0.006256233435124159, -0.04334951937198639, -0.058670755475759506, -0.04043175280094147, 0.04007871076464653, 0.030023612082004547, -0.024001184850931168, -0.006595192477107048, -0.004537835251539946, 0.02731829695403576, -0.012602586299180984, 0.01061569806188345, 0.004760629031807184, 0.00455853808671236, 0.0019285212038084865, 0.022722473368048668, 0.0034692143090069294, -0.09061118215322495, 0.018749995157122612, 0.010343603789806366, 0.02006787434220314, 0.011537781916558743, 0.03256494924426079, -0.044080160558223724, -0.027749355882406235, 0.030642276629805565, 0.04763781279325485, 0.023257916793227196, 0.0015603716019541025, 0.03834407031536102, -0.08569438755512238, -0.03879742696881294, 0.027494465932250023, -0.09094654023647308, -0.038457076996564865, -0.03509476035833359, -0.06532427668571472, -0.05433306470513344, -0.031463343650102615, -0.008837921544909477, 0.018688151612877846, -0.04672490432858467, -0.008673994801938534, -0.023971259593963623, -0.12519551813602448, -0.037664081901311874, -0.04747124761343002, -0.02493242360651493, -0.005760116968303919, -0.047024961560964584, -0.048905666917562485, -0.09148150682449341, 0.06872063875198364, -0.01667449064552784, 0.03328897804021835, -0.091104656457901, -0.07494015991687775, 0.009356865659356117, 0.017217738553881645, -0.0014292175183072686, 0.01650744304060936, -0.013303915970027447, -0.017205992713570595, -0.012537906877696514, 0.054821182042360306, 0.05161937326192856, -0.01804378814995289, -0.00896431040018797, 0.01653553545475006, -0.015933185815811157, -0.04107922688126564, 0.05235143378376961, 0.03488701954483986, -0.069034643471241, -0.018574291840195656, 0.012515869922935963, -0.029338670894503593, -0.02714359015226364, 0.010133172385394573, -0.03877225145697594, 0.001842998550273478, 0.009036222472786903, 0.03382834792137146, 0.010421440936625004, -0.043590933084487915, 0.14444060623645782, 0.020706798881292343, 0.02583545818924904, -0.004425066523253918, -0.031711503863334656, 0.05829077586531639, 0.021748436614871025, 0.016675010323524475, -0.045985180884599686, -0.014037192799150944, 0.028305044397711754, -0.02063417248427868, -0.03387164697051048, 0.016290277242660522, 0.04454869031906128, 0.004296662751585245, 0.0020803932566195726, -0.06345134973526001, -0.03363726660609245, -0.05675606429576874, 0.04378223046660423, -0.018467526882886887, -0.04529864341020584, 0.021651137620210648, 0.07270945608615875, 0.011301951482892036, 0.07809829711914062, -0.007224865723401308, 0.04768993705511093, -0.001152798649854958, -0.003363669151440263, 0.035657092928886414, 0.014340966008603573, 0.010118329897522926, 0.019405735656619072, -0.030906688421964645, 0.022117629647254944, 0.020069560036063194, 0.03871043771505356, -0.05061168968677521, 0.008365803398191929, -0.07450806349515915, -0.013298684731125832, 0.01404271088540554, -0.028912164270877838, 0.06829457730054855, 0.017493845894932747, 0.03308245539665222, 0.008368310518562794, 0.05939105153083801, 0.021174084395170212, -0.07301054149866104, 0.010714393109083176, -0.05964544415473938, 0.015617060475051403, 0.0009478717693127692, -0.036753181368112564, -0.016644839197397232, -0.0163116417825222, -0.001748336129821837, 0.02933065965771675, 0.016418829560279846, -0.003531829686835408, 0.05252828821539879, 0.0038721305318176746, -0.019156280905008316, -0.0026973041240125895, -0.013379895128309727, -0.05984901636838913, -0.030665621161460876, 0.053940244019031525, -0.016361145302653313, -0.04924245923757553, -0.01851893588900566, 0.025207391008734703, 0.03874535486102104, -0.10985184460878372, 0.024212026968598366, -0.04444646090269089, -0.005658643785864115, 0.002151206601411104, -0.024982817471027374, -0.003346238052472472, -0.03459760919213295, -0.04505692049860954, 0.006780047435313463, 0.08039429038763046, 0.015950366854667664, 0.009259114973247051, -0.03579569235444069, -0.020655879750847816, -0.06054537370800972, -0.01909482851624489, 0.01150190643966198, 0.020090898498892784, -0.05674648657441139, 0.004536085296422243, 0.03534189611673355, -0.014443375170230865, -0.020264185965061188, -0.022814296185970306, -0.01523847971111536, -0.013325170613825321, -0.01317358948290348, 0.03007747232913971, 0.030261646956205368, -0.03614001348614693, 0.0028940073680132627, 0.023046448826789856, -0.04834150895476341, 0.015049304813146591, -0.018307175487279892, 0.050611235201358795, 0.008619063533842564, -0.018413130193948746, -0.015421083196997643, 0.03478066995739937, 0.039174094796180725, -0.06330978125333786, -0.03174985945224762, -0.033581674098968506, -0.021274806931614876, -0.005133785307407379, 0.0021207351237535477, -0.014110376127064228, -0.015123117715120316, 0.011856802739202976, -0.015094191767275333, -0.003098446410149336, 0.011642098426818848, 0.0008322101202793419, -0.008056887425482273, -0.017790522426366806, 0.01861160434782505, 0.027593156322836876, -0.0595025010406971, 0.075432687997818, -0.007718878798186779, 0.06785266101360321, -0.07696665078401566, 0.01946403644979, 0.07803298532962799, -0.005010245833545923, 0.03845048323273659, 0.030651018023490906, -0.013480812311172485, 0.0066271317191421986, 0.017924627289175987, 0.02814287133514881, -0.023468945175409317, 0.014419217593967915, 0.03565497323870659, 0.0059437220916152, 0.01148063875734806, 0.019645389169454575, -0.006691786460578442, 0.016292616724967957, 0.04940635710954666, 0.010778257623314857, 0.004679578356444836, -0.0021605074871331453, 0.001758165773935616, 0.003516064491122961, -0.040745511651039124, 0.015658516436815262, 0.07798667997121811, 0.01734553836286068, -0.022587154060602188, -0.03181881457567215, 0.01297843549400568, 0.008763999678194523, 0.037050820887088776, -0.042591143399477005, -0.04125509783625603, -0.09041237086057663, 0.012124940752983093, -0.027637474238872528, 0.0031099137850105762, 0.005967955105006695, -0.040780290961265564, 0.0069716027937829494, 0.002336385427042842, -0.038105178624391556, -0.005655298940837383, 0.06780607998371124, 0.029937520623207092, 0.006178990472108126, -0.04550010710954666, 0.04808075726032257, -0.016438625752925873, 0.027952397242188454, 0.03537800535559654, -0.08684936910867691, 0.0144730806350708, -0.020088253542780876, -0.016375832259655, 0.03170976787805557, 0.01320032961666584, 0.009875264950096607, -0.03470961004495621, 0.017959710210561752, 0.027309788390994072, 0.06063329800963402, 0.030199380591511726, 0.008155211806297302, -0.00303186709061265, 0.0464731827378273, 0.04143741726875305, 0.04596181958913803, -0.035027891397476196, -0.03502493351697922, -0.012694860808551311, 0.03974113613367081, 0.04695328697562218, 0.012157402001321316, -0.006235972978174686, 0.009937988594174385, 0.0022887075319886208, -0.024850893765687943, 0.004085088148713112, 0.015656329691410065, 0.03525649011135101, 0.025153974071145058, 0.02285732887685299, -0.019055822864174843, -0.012813462875783443, -0.012874336913228035, 0.003058894770219922, 0.002380638848990202, 0.009701540693640709, 0.006452794186770916, -0.007842281833291054, -0.022793374955654144, -0.0033788266591727734, 0.03455715626478195, 0.023212958127260208, 0.02027936466038227, 0.0032892015296965837, -0.024363970384001732, -0.003862298559397459, -0.005688998848199844, 0.012445392087101936, 0.07049525529146194, 0.011022435501217842, -0.03036927804350853, 0.07607065886259079, -0.027038561180233955, -0.02478676848113537, -0.008760647848248482, -0.0087134949862957, 0.0014079671818763018, -0.04708043113350868, 0.014987211674451828, 0.013280162587761879, -0.003971757832914591, -0.046244118362665176, -0.02741069905459881, 0.017102418467402458, -0.07717471569776535, 0.027046434581279755, -0.02987850457429886, -0.04992779716849327, -0.010421382263302803, -0.013909462839365005, 0.0012499255826696754, -0.03270814195275307, 0.06032361462712288, -0.06632599979639053, 0.06374277174472809, 0.011486450210213661, -0.02391752414405346, -0.03699517250061035, -0.004502549301832914, 0.002541458932682872, -0.001359647372737527, 0.03640468791127205, -0.007254268042743206, -0.00980154424905777, 0.0012152136769145727, -0.021689467132091522, -0.01477163378149271, -0.02874681167304516, -0.015597322024405003, -0.053558263927698135, 0.024352282285690308, -0.03496815636754036, -0.013501823879778385, -0.000500476686283946, 0.025815928354859352, 0.05795910581946373, 0.021254222840070724, -0.031679969280958176, 0.030894888564944267, 0.03793121129274368, -0.021174481138586998, 0.015057004988193512, -0.020416826009750366, -0.023162255063652992, 0.0032795679289847612, -0.043975695967674255, -0.045997362583875656, -0.03876039385795593, -0.05577843263745308, -0.050913773477077484, 0.0008593962411396205, 0.07356373220682144, 0.008594735525548458, 0.000329879141645506, -0.018356462940573692, -0.02328357845544815, 0.0057863499969244, 0.019888250157237053, -0.07144659757614136, 0.11006931960582733, 0.010742038488388062, -0.03763584792613983, -0.059824664145708084, 0.006702701561152935, -4.0998933400260285e-05, 0.01875309646129608, 0.02349509671330452, -0.016865652054548264, 0.03161481395363808, 0.019760888069868088, 0.018501343205571175, -0.016086718067526817, -0.08262619376182556, -0.006598097272217274, -0.01054003369063139, 0.02613825909793377, 0.012677486054599285, -0.01750093512237072, -0.003376623149961233, 0.012791895307600498, 0.07449612021446228, 0.008708100765943527, 0.02146822400391102, 0.05345414951443672, -0.03866979852318764, -0.003651416627690196, -0.01519770734012127, -0.056546036154031754, 0.04290507361292839, -0.07500240206718445, -0.012898208573460579, -0.009680845774710178, -0.040962692350149155, -0.0023976080119609833, 0.04448065161705017, 0.00394388847053051, 0.00951681099832058, -0.008921599015593529, 0.016448475420475006, 0.0808267816901207, 0.023158758878707886, 0.038396794348955154, -0.025005724281072617, 0.029744410887360573, 0.019178414717316628, 0.019986731931567192, -0.011063278652727604, -0.016266288235783577, 0.0037582581862807274, -0.023918751627206802, 0.030819570645689964, -0.0120036406442523, 0.014820883050560951, 0.015855690464377403, 0.0015415562083944678, 0.038025420159101486, 0.0038948541041463614, 0.0372576043009758, 0.03606081008911133, 0.03330150619149208, 0.06565264612436295, 0.012623070739209652, 0.09541277587413788, 0.03116878680884838, -0.008016525767743587, -0.021637795493006706, -0.048308998346328735, -0.042428478598594666, 0.022239139303565025, -0.00801138486713171, -0.03497127816081047, -0.05813417583703995, 0.05768003687262535, -0.008338801562786102, -0.08255797624588013, 0.04806128889322281, 0.04154077544808388, -0.002707043429836631, -0.0325307622551918, 0.02555071748793125, -0.03429224342107773, 0.0033270353451371193, -0.0043534995056688786, 0.016145486384630203, 0.020666826516389847, 0.004006237722933292, 0.015513488091528416, -0.024600166827440262, 0.016215045005083084, 0.02302415482699871, 0.008756676688790321, 0.055370330810546875, -0.014512783847749233, -0.03200940415263176, 0.04375283420085907, 0.012268240563571453, 0.007839097641408443, -0.01574462652206421, 0.0008527508471161127, -0.016455812379717827, -0.057670313864946365, -0.00978691503405571, 0.011127794161438942, -0.017389189451932907, 0.03328930214047432, 0.03454207256436348, -0.02815442904829979, -0.010409023612737656, -0.007066528312861919, -0.015230873599648476, -0.05291898921132088, 0.003658448811620474, -0.026806462556123734, 0.024513110518455505, -0.08057603985071182, -0.013543633744120598, -0.03764832764863968, -0.014839998446404934, -0.016773588955402374, -0.009355472400784492, -0.00035033936728723347, 0.00032372772693634033, 0.009436927735805511, 0.023785654455423355, 0.013179478235542774, -0.014699336141347885, 0.025315584614872932, 0.04343352094292641, 0.011514085344970226, 0.05305500701069832, 0.034713659435510635, -0.004847103264182806, -0.023860005661845207, 0.05505302920937538, -0.05579181760549545, 0.01663595251739025, -0.006865639239549637, 0.015437720343470573, 0.02336670458316803, 0.04099564626812935, 0.043956492096185684, 0.0030288416892290115, -0.023823494091629982, 0.013820461928844452, 0.019885344430804253, 0.01696898229420185, 0.03580883517861366, -0.025397103279829025, -0.020725246518850327, -0.006519826129078865, -0.037464629858732224, -0.010087767615914345, -0.04047490283846855, 0.019351428374648094, 0.0076317572966217995, 0.018050847575068474, 0.0036526445765048265, 0.0012127819936722517, -0.04778434708714485, 0.0006189910345710814, 0.008006623946130276, 0.011382142081856728, -0.013441096991300583, -0.044019173830747604, -0.005157413426786661, -0.04246729612350464, -0.028149692341685295, -0.054328616708517075, -0.015797048807144165, 0.06244376301765442, 0.018587157130241394, -0.007781204767525196, 0.009052137844264507, -0.011257652193307877, 0.03090163879096508, 0.061131324619054794, -0.027437085285782814, 0.012208516709506512, -0.05719533935189247, 0.051723040640354156, 0.05731052905321121, -0.013011621311306953, 0.052600376307964325, -0.019513098523020744, 0.02369101531803608]\n",
      "Response: [[MatchNeighbor(id='8f77d2da-9143-4173-9404-dbff7bc231b7', distance=0.7146891355514526, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]), MatchNeighbor(id='f4c0c705-037e-4073-a1a0-859434f5d151', distance=0.7056695222854614, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[]), MatchNeighbor(id='46b1ef3f-edf5-47e4-86df-2a1d207358c3', distance=0.7039259672164917, sparse_distance=None, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[], sparse_embedding_values=[], sparse_embedding_dimensions=[])]]\n",
      "Matched IDs: ['8f77d2da-9143-4173-9404-dbff7bc231b7', 'f4c0c705-037e-4073-a1a0-859434f5d151', '46b1ef3f-edf5-47e4-86df-2a1d207358c3']\n",
      "Q: What is RREGOP?\n",
      "A: RREGOP is the Régime de retraite du personnel employé du gouvernement et des organismes publics (Retirement Plan for Employees of the Government and Public Organizations).  It covers regular and casual employees working full-time or part-time in the health and social services network, the education network, and the Quebec public service.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "question = \"What is RREGOP?\"\n",
    "answer = search_and_answer(question)\n",
    "print(f\"Q: {question}\\nA: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
